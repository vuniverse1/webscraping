{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8b592-0f2e-41e3-8072-1263b445dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Base URL for company job listings\n",
    "base_url = 'https://www.bain.com/careers/find-a-role/'\n",
    "\n",
    "# TODO: Define the pull_company_name function\n",
    "def pull_company_name(base_url, all_links, job_links):\n",
    "    \"\"\"\n",
    "    Extracts job links from the company careers page.\n",
    "\n",
    "    Parameters:\n",
    "    base_url (str): The base URL of the company careers page.\n",
    "    all_links (list): List of all links on the current page.\n",
    "    job_links (list): List of collected job links.\n",
    "\n",
    "    Returns:\n",
    "    list: Updated list of job links.\n",
    "    \"\"\"\n",
    "    for link in all_links:\n",
    "        # TODO: Check if the link contains a certain pattern and is not already in job_links\n",
    "        # Append the link to job_links if it meets the criteria\n",
    "        pass\n",
    "    return job_links\n",
    "\n",
    "# TODO: Define the button_company_name function\n",
    "def button_company_name(driver, page, outer_loop_break, all_links):\n",
    "    \"\"\"\n",
    "    Handles pagination by clicking the \"next page\"/\"load more\" button.\n",
    "\n",
    "    Parameters:\n",
    "    driver (WebDriver): The Selenium WebDriver instance.\n",
    "    page (int): The current page number. (optional)\n",
    "    outer_loop_break (bool): Flag to indicate when to stop scraping.\n",
    "    all_links (list): List of all links on the current page.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Updated page number and outer_loop_break flag.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # TODO: Locate the next page button and navigate to the next page if it exists\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while trying to click the 'next page' button: {e}\")\n",
    "        outer_loop_break = True\n",
    "    return page + 1, outer_loop_break\n",
    "\n",
    "# WebDriver setup\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(base_url)\n",
    "\n",
    "# Initialize variables\n",
    "job_links = []\n",
    "prev_page = 0\n",
    "page = 1\n",
    "\n",
    "# Main scraping loop\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    outer_loop_break = False\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    all_links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "    # Scrape job links\n",
    "    job_links = pull_company_name(base_url, all_links, job_links)\n",
    "\n",
    "    # Handle pagination\n",
    "    page, outer_loop_break = button_company_name(driver, page, outer_loop_break, all_links)\n",
    "\n",
    "    if outer_loop_break:\n",
    "        break\n",
    "\n",
    "# Output the collected job links\n",
    "print(\"Collected job links:\", job_links)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
